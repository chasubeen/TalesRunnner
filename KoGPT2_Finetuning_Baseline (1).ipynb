{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27d284e946944b709271fe395b547a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8fea807445b94d0eb06ea0ee53cf34b8",
              "IPY_MODEL_6be10a71cd9c4463b0f9275c0c313f22",
              "IPY_MODEL_ed0a2bba862445bea230730375aef642"
            ],
            "layout": "IPY_MODEL_5f38d9373c79403b93fb1e2faedaa5ed"
          }
        },
        "8fea807445b94d0eb06ea0ee53cf34b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ff3050732744259a6a7bb60682a48af",
            "placeholder": "​",
            "style": "IPY_MODEL_a3de72723a7a4560a322aaa9d21ac6f4",
            "value": "tokenizer.json: 100%"
          }
        },
        "6be10a71cd9c4463b0f9275c0c313f22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81ae1a0cc5ca4fee8c2e63b78d8acc90",
            "max": 2825034,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e5c4a7a41faa46078bd6418d8d6dc331",
            "value": 2825034
          }
        },
        "ed0a2bba862445bea230730375aef642": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ebcdf2cce846f789e8f006701d15f6",
            "placeholder": "​",
            "style": "IPY_MODEL_5d1818fb20c94677b956a22f6c97023e",
            "value": " 2.83M/2.83M [00:00&lt;00:00, 17.1MB/s]"
          }
        },
        "5f38d9373c79403b93fb1e2faedaa5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff3050732744259a6a7bb60682a48af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3de72723a7a4560a322aaa9d21ac6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "81ae1a0cc5ca4fee8c2e63b78d8acc90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5c4a7a41faa46078bd6418d8d6dc331": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "27ebcdf2cce846f789e8f006701d15f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1818fb20c94677b956a22f6c97023e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f075b2ac14a149759f6599ccf04793c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc1e3b4d041c486fb53a2a14fc7d02a4",
              "IPY_MODEL_371ea14853f84dd0946c96673b39f00c",
              "IPY_MODEL_7f40d64838414276829a167fb9c9116e"
            ],
            "layout": "IPY_MODEL_48595dc9bfc9428e950ea1c27575d449"
          }
        },
        "cc1e3b4d041c486fb53a2a14fc7d02a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd87d36a2a2e493bb63a38884cefd357",
            "placeholder": "​",
            "style": "IPY_MODEL_3ea6a66b841344ad8018fa6422b0511c",
            "value": "config.json: 100%"
          }
        },
        "371ea14853f84dd0946c96673b39f00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f011fcdba09d4e7b88825e5eb8a5f9df",
            "max": 1000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f637c4b665947209dc9ba23db63356e",
            "value": 1000
          }
        },
        "7f40d64838414276829a167fb9c9116e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83da7845a0134a9c8c7d55fa11c30bdc",
            "placeholder": "​",
            "style": "IPY_MODEL_37944c75a22643fe9f4475d1c9c5dd24",
            "value": " 1.00k/1.00k [00:00&lt;00:00, 59.0kB/s]"
          }
        },
        "48595dc9bfc9428e950ea1c27575d449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd87d36a2a2e493bb63a38884cefd357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ea6a66b841344ad8018fa6422b0511c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f011fcdba09d4e7b88825e5eb8a5f9df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f637c4b665947209dc9ba23db63356e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83da7845a0134a9c8c7d55fa11c30bdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37944c75a22643fe9f4475d1c9c5dd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8089547bbc0243c7965366710235edc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1407c29fe8d3401bbbc70784d070b98a",
              "IPY_MODEL_eb34cd1e78a34f269a61cd189a6246f3",
              "IPY_MODEL_8bbeb638bef543798a69e080c9fb1aab"
            ],
            "layout": "IPY_MODEL_31910d5682424562b73ced019fe6732c"
          }
        },
        "1407c29fe8d3401bbbc70784d070b98a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcbfc975861d4a6d9540b1111fac229c",
            "placeholder": "​",
            "style": "IPY_MODEL_a8955fff2d4b4e9081a94ea89e0017bd",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "eb34cd1e78a34f269a61cd189a6246f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c55c3ef14334ebd8df4c6e5108c76c2",
            "max": 513302779,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04ad093646844f1f96d82353b22f9fc4",
            "value": 513302779
          }
        },
        "8bbeb638bef543798a69e080c9fb1aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2dc0598ca51485f84b455e5a41aae1f",
            "placeholder": "​",
            "style": "IPY_MODEL_f10a5a3cd1f944e59875186d05aa2303",
            "value": " 513M/513M [00:07&lt;00:00, 39.1MB/s]"
          }
        },
        "31910d5682424562b73ced019fe6732c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dcbfc975861d4a6d9540b1111fac229c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8955fff2d4b4e9081a94ea89e0017bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4c55c3ef14334ebd8df4c6e5108c76c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ad093646844f1f96d82353b22f9fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2dc0598ca51485f84b455e5a41aae1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10a5a3cd1f944e59875186d05aa2303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 참고 링크\n",
        "- https://wikidocs.net/157896\n",
        "-"
      ],
      "metadata": {
        "id": "Zjx2FvR93GW6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Jn8W3o5FdLv",
        "outputId": "cf6c6645-840d-4e36-a18d-c90baef39b4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "source": [
        "# 패키지 설치\n",
        "!pip install transformers torch sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS5Xa_tC31jT",
        "outputId": "5a7c3eec-95a0-490c-fc4e-071143e0ccbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelWithLMHead, PreTrainedTokenizerFast # KoGPT2에 맞춰 사전 훈련된 토크나이저\n",
        "from fastai.text.all import *\n",
        "import fastai\n",
        "import re\n",
        "\n",
        "print(torch.__version__)\n",
        "print(transformers.__version__)\n",
        "print( fastai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kchwsrVmJR5E",
        "outputId": "6a0ec998-d8ad-4bfa-eab4-bc11f72b2fd0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "4.47.1\n",
            "2.7.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. 데이터 전처리**\n",
        "\n",
        "- 필수 및 선택 필드 정의\n",
        "- 선택 필드의 결측치는 ```<empty>```로 채움"
      ],
      "metadata": {
        "id": "DNqpPCrWKbCe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 로드 및 전처리\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# 필수 및 선택 필드 정의\n",
        "required_fields = ['caption', 'name', 'i_action', 'classification']\n",
        "optional_fields = [\n",
        "    'character', 'setting', 'action', 'feeling',\n",
        "    'causalRelationship', 'outcomeResolution', 'prediction'\n",
        "]\n",
        "\n",
        "def preprocess_data(file_path):\n",
        "    # 데이터 로드\n",
        "    df = pd.read_csv(file_path, encoding='cp949')\n",
        "\n",
        "    # 결측치 처리 (선택 필드는 <empty>)\n",
        "    df.fillna('<empty>', inplace=True)\n",
        "\n",
        "    # 입력 텍스트 생성 함수\n",
        "    def generate_input_text(row):\n",
        "        # 필수 필드 검증 (결측값 확인)\n",
        "        for field in required_fields:\n",
        "            assert pd.notna(row[field]) and row[field].strip(), f\"Error: 필수 필드 {field}가 비어 있습니다.\"\n",
        "\n",
        "        # 필수 필드 설정\n",
        "        input_tokens = [\n",
        "            f\"[caption] {row['caption']}\",\n",
        "            f\"[name] {row['name']}\",\n",
        "            f\"[i_action] {row['i_action']}\",\n",
        "            f\"[classification] {row['classification']}\"\n",
        "        ]\n",
        "\n",
        "        # 선택 필드 처리 (값이 없으면 <empty>)\n",
        "        for field in optional_fields:\n",
        "            token_value = row[field] if pd.notna(row[field]) and row[field].strip() else \"<empty>\"\n",
        "            input_tokens.append(f\"[{field}] {token_value}\")\n",
        "\n",
        "        # 행별 랜덤 시드 설정 (일관성 유지)\n",
        "        unique_id = row[\"id\"] if \"id\" in row else row.name  # id가 없으면 인덱스 사용\n",
        "        random.seed(unique_id)\n",
        "\n",
        "        # 선택 필드 랜덤 섞기\n",
        "        random.shuffle(optional_fields)\n",
        "\n",
        "\n",
        "\n",
        "        # 최종 텍스트 구성\n",
        "        return \" \".join(input_tokens + optional_fields)\n",
        "\n",
        "    # input_text 및 target_text 컬럼 생성\n",
        "    df['input_text'] = df.apply(generate_input_text, axis=1)\n",
        "    df['target_text'] = df['srcText']\n",
        "\n",
        "    return df\n",
        "\n",
        "# 파일 경로 설정\n",
        "train_file_path = '/content/drive/MyDrive/7th-project/data/train_sample.csv'\n",
        "val_file_path = '/content/drive/MyDrive/7th-project/data/val_sample.csv'\n",
        "\n",
        "# 전처리 적용\n",
        "df_train = preprocess_data(train_file_path)\n",
        "df_val = preprocess_data(val_file_path)\n",
        "\n",
        "# 데이터 확인\n",
        "print(df_train[['input_text', 'target_text']].head())\n",
        "print(df_val[['input_text', 'target_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnXcy9ym7Ntz",
        "outputId": "5e15760b-cd5f-4a5b-b5e5-efa9874fb026"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                                                                                                                                                                                                                                                                          input_text  \\\n",
            "0             [caption] 숲속의 나비 [name] 나비 [i_action] 날다 [classification] 자연탐구 [character] 아름다운 나비 [setting] 숲속 [action] 춤추다 [feeling] 기쁨 [causalRelationship] 숲속의 바람이 나비를 춤추게 했다. [outcomeResolution] 숲속의 나비는 행복했다. [prediction] 나비는 또 다른 꽃을 찾을 것이다. feeling prediction outcomeResolution action character causalRelationship setting   \n",
            "1                            [caption] 바다의 고래 [name] 고래 [i_action] 유영하다 [classification] 자연탐구 [feeling] 평화 [prediction] <empty> [outcomeResolution] 고래는 바다를 사랑하게 되었다. [action] <empty> [character] 거대한 고래 [causalRelationship] <empty> [setting] 바다 outcomeResolution action prediction character causalRelationship feeling setting   \n",
            "2                [caption] 하늘의 새 [name] 새 [i_action] 날다 [classification] 자연탐구 [outcomeResolution] <empty> [action] 날아오르다 [prediction] 새는 구름 위로 올라갈 것이다. [character] <empty> [causalRelationship] 하늘의 바람이 새를 떠오르게 했다. [feeling] <empty> [setting] 하늘 outcomeResolution prediction character setting feeling causalRelationship action   \n",
            "3                         [caption] 밤하늘의 별 [name] 별 [i_action] 반짝이다 [classification] 예술경험 [outcomeResolution] 별은 밤하늘에서 더 반짝이게 되었다. [prediction] <empty> [character] 반짝이는 별 [setting] <empty> [feeling] 감탄 [causalRelationship] <empty> [action] 빛나다 causalRelationship feeling action setting outcomeResolution character prediction   \n",
            "4  [caption] 초원의 사자 [name] 사자 [i_action] 쉬다 [classification] 자연탐구 [causalRelationship] 초원의 바람이 사자를 쉬게 했다. [feeling] <empty> [action] <empty> [setting] 초원 [outcomeResolution] 사자는 초원에서 평온함을 느꼈다. [character] <empty> [prediction] 사자는 가족과 함께 쉴 것이다. prediction setting feeling causalRelationship character action outcomeResolution   \n",
            "\n",
            "                  target_text  \n",
            "0      나비는 숲속에서 춤추듯 날고 있었습니다.  \n",
            "1  고래는 바다 속 깊은 곳을 유영하고 있었습니다.  \n",
            "2    새는 푸른 하늘을 자유롭게 날고 있었습니다.  \n",
            "3        별은 밤하늘에서 반짝이고 있었습니다.  \n",
            "4      사자는 초원에서 고요히 쉬고 있었습니다.  \n",
            "                                                                                                                                                                                                                                                                                                                  input_text  \\\n",
            "0      [caption] 바람 속의 연 [name] 연 [i_action] 날다 [classification] 자연탐구 [outcomeResolution] 연은 더 높이 날아올랐다. [feeling] 자유 [causalRelationship] 바람이 연을 높이 날게 했다. [setting] 바람 [prediction] 연은 더 멀리 날아갈 것이다. [action] <empty> [character] 높이 나는 연 feeling outcomeResolution causalRelationship action character prediction setting   \n",
            "1  [caption] 숲속의 여우 [name] 여우 [i_action] 움직이다 [classification] 자연탐구 [feeling] <empty> [outcomeResolution] 여우는 숲에서 더 안전해졌다. [causalRelationship] <empty> [action] 조용히 움직이다 [character] 조용한 여우 [prediction] 여우는 새로운 은신처를 찾을 것이다. [setting] 숲속 setting outcomeResolution feeling prediction character causalRelationship action   \n",
            "2      [caption] 강물의 물고기 [name] 물고기 [i_action] 헤엄치다 [classification] 자연탐구 [setting] 강물 [outcomeResolution] <empty> [feeling] 평화 [prediction] 물고기는 강물 속에서 새로운 친구를 만날 것이다. [character] <empty> [causalRelationship] <empty> [action] 유유히 헤엄치다 prediction setting causalRelationship character outcomeResolution action feeling   \n",
            "3             [caption] 바다의 파도 [name] 파도 [i_action] 밀려오다 [classification] 자연탐구 [prediction] <empty> [setting] 바다 [causalRelationship] 바다의 바람이 파도를 밀어냈다. [character] <empty> [outcomeResolution] <empty> [action] 힘차게 밀려오다 [feeling] <empty> feeling causalRelationship character setting action outcomeResolution prediction   \n",
            "4      [caption] 하늘의 구름 [name] 구름 [i_action] 흘러가다 [classification] 자연탐구 [feeling] 평온 [causalRelationship] 하늘의 바람이 구름을 흘러가게 했다. [character] <empty> [setting] 하늘 [action] <empty> [outcomeResolution] 구름은 하늘에 평화를 가져왔다. [prediction] <empty> prediction character setting outcomeResolution action feeling causalRelationship   \n",
            "\n",
            "                   target_text  \n",
            "0    연은 바람 속에서 높이 날아오르고 있었습니다.  \n",
            "1     여우는 숲속에서 조용히 움직이고 있었습니다.  \n",
            "2  물고기는 강물 속에서 유유히 헤엄치고 있었습니다.  \n",
            "3     파도는 바다에서 힘차게 밀려오고 있었습니다.  \n",
            "4     구름은 하늘에서 천천히 흘러가고 있었습니다.  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. KoGPT2 모델 준비**\n",
        "- **토크나이저 준비 및 특수 토큰 추가**: 모델이 데이터에서 사용되는 태그([caption], [name] 등)를 인식하도록 특수 토큰을 추가\n",
        "\n",
        "- KoGPT2 모델을 로드하고, 새롭게 추가된 토큰을 반영하도록 임베딩 크기를 조정"
      ],
      "metadata": {
        "id": "Mw9QsMBmKys0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "# KoGPT2 토크나이저 불러오기\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\",\n",
        "    bos_token='</s>', eos_token='</s>', unk_token='<unk>',\n",
        "    pad_token='<pad>', mask_token='<mask>'\n",
        ")\n",
        "\n",
        "# 사용자 정의 special tokens\n",
        "special_tokens_dict = {\n",
        "    'additional_special_tokens': [\n",
        "        \"[caption]\", \"[name]\", \"[i_action]\", \"[classification]\",\n",
        "        \"[character]\", \"[setting]\", \"[action]\", \"[feeling]\",\n",
        "        \"[causalRelationship]\", \"[outcomeResolution]\", \"[prediction]\",\n",
        "        \"<empty>\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# 토크나이저에 특수 토큰 추가\n",
        "tokenizer.add_special_tokens(special_tokens_dict)\n",
        "\n",
        "# 확인: 특수 토큰이 정상적으로 추가되었는지 확인\n",
        "print(\"Special tokens added:\", tokenizer.special_tokens_map)\n",
        "print(\"Vocabulary size:\", len(tokenizer))\n",
        "\n",
        "# 모델 로드 (사전 학습된 모델)\n",
        "model = GPT2LMHeadModel.from_pretrained(\"skt/kogpt2-base-v2\")\n",
        "\n",
        "# 모델의 임베딩 크기를 조정 (새로운 토큰 개수 추가)\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "# GPU 설정\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "print(\"Model and tokenizer loaded successfully.\")\n",
        "\n",
        "# 토크나이저 저장\n",
        "#tokenizer.save_pretrained(\"./fine_tuned_kogpt2_tokenizer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372,
          "referenced_widgets": [
            "27d284e946944b709271fe395b547a23",
            "8fea807445b94d0eb06ea0ee53cf34b8",
            "6be10a71cd9c4463b0f9275c0c313f22",
            "ed0a2bba862445bea230730375aef642",
            "5f38d9373c79403b93fb1e2faedaa5ed",
            "6ff3050732744259a6a7bb60682a48af",
            "a3de72723a7a4560a322aaa9d21ac6f4",
            "81ae1a0cc5ca4fee8c2e63b78d8acc90",
            "e5c4a7a41faa46078bd6418d8d6dc331",
            "27ebcdf2cce846f789e8f006701d15f6",
            "5d1818fb20c94677b956a22f6c97023e",
            "f075b2ac14a149759f6599ccf04793c6",
            "cc1e3b4d041c486fb53a2a14fc7d02a4",
            "371ea14853f84dd0946c96673b39f00c",
            "7f40d64838414276829a167fb9c9116e",
            "48595dc9bfc9428e950ea1c27575d449",
            "fd87d36a2a2e493bb63a38884cefd357",
            "3ea6a66b841344ad8018fa6422b0511c",
            "f011fcdba09d4e7b88825e5eb8a5f9df",
            "3f637c4b665947209dc9ba23db63356e",
            "83da7845a0134a9c8c7d55fa11c30bdc",
            "37944c75a22643fe9f4475d1c9c5dd24",
            "8089547bbc0243c7965366710235edc8",
            "1407c29fe8d3401bbbc70784d070b98a",
            "eb34cd1e78a34f269a61cd189a6246f3",
            "8bbeb638bef543798a69e080c9fb1aab",
            "31910d5682424562b73ced019fe6732c",
            "dcbfc975861d4a6d9540b1111fac229c",
            "a8955fff2d4b4e9081a94ea89e0017bd",
            "4c55c3ef14334ebd8df4c6e5108c76c2",
            "04ad093646844f1f96d82353b22f9fc4",
            "a2dc0598ca51485f84b455e5a41aae1f",
            "f10a5a3cd1f944e59875186d05aa2303"
          ]
        },
        "id": "dPTMK7yo4qAU",
        "outputId": "f5e93078-0ca7-4c83-cf10-3c86953ce590"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27d284e946944b709271fe395b547a23"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.00k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f075b2ac14a149759f6599ccf04793c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
            "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Special tokens added: {'bos_token': '</s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<pad>', 'mask_token': '<mask>', 'additional_special_tokens': ['[caption]', '[name]', '[i_action]', '[classification]', '[character]', '[setting]', '[action]', '[feeling]', '[causalRelationship]', '[outcomeResolution]', '[prediction]', '<empty>']}\n",
            "Vocabulary size: 51212\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/513M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8089547bbc0243c7965366710235edc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and tokenizer loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. 데이터셋 및 데이터로더 구성**\n",
        "\n",
        "- PyTorch ```Dataset```을 활용하여 input_text와 target_text를 각각 토큰화하고, 데이터로더(DataLoader)를 생성\n",
        "\n",
        "- 데이터의 패딩, 길이 조정 및 PyTorch 텐서로 변환"
      ],
      "metadata": {
        "id": "s47SGxG8LD83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 클래스 정의\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class StoryDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if 'input_text' not in self.data.columns or 'target_text' not in self.data.columns:\n",
        "            raise KeyError(\"데이터셋에 'input_text' 또는 'target_text' 컬럼이 없습니다.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)  # 데이터 크기 반환\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data.iloc[index]\n",
        "\n",
        "        input_text = row['input_text']\n",
        "        target_text = row['target_text']\n",
        "\n",
        "        # 입력 텍스트 및 타겟 텍스트를 별도로 토큰화\n",
        "        encoding = self.tokenizer(\n",
        "            input_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        target_encoding = self.tokenizer(\n",
        "            target_text,\n",
        "            max_length=self.max_length,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        input_ids = encoding[\"input_ids\"].squeeze(0)\n",
        "        attention_mask = encoding[\"attention_mask\"].squeeze(0)\n",
        "        labels = target_encoding[\"input_ids\"].squeeze(0)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n"
      ],
      "metadata": {
        "id": "n95VTCeJuiRA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터셋 및 데이터로더 생성\n",
        "train_dataset = StoryDataset(df_train, tokenizer, max_length=256)\n",
        "val_dataset = StoryDataset(df_val, tokenizer, max_length=256)\n",
        "\n",
        "# DataLoader 설정\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8)\n",
        "\n",
        "# 데이터 확인\n",
        "for batch in train_dataloader:\n",
        "    print(batch[\"input_ids\"].shape)\n",
        "    break\n"
      ],
      "metadata": {
        "id": "kNM4XmB0yabQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3177b33a-8ace-4802-9778-395e6da7a3ff"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. 모델 학습**\n",
        "\n",
        "- AdamW 옵티마이저와 크로스 엔트로피 손실 함수를 사용하여 모델 학습"
      ],
      "metadata": {
        "id": "XgfxhzofLUMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AdamW\n",
        "\n",
        "# GPU 설정 (GPU 없으 CPU 사용)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 옵티마이저 설정 (AdamW 사용)\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "# 손실 함수\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "\n",
        "# 학습 관련 파라미터 설정\n",
        "epochs = 20\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Early Stopping 설정\n",
        "early_stopping_patience = 3  # 검증 손실 개선 없을 시 조기 종료 기준\n",
        "best_val_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # 모델을 학습 모드로 설정\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # 기존의 gradient 초기화\n",
        "\n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()  # 가중치 업데이트\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "    print(f\"Epoch {epoch + 1}, Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # 검증 단계\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "\n",
        "    with torch.no_grad():  # 검증 단계에서는 gradient 계산을 하지 않음\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            labels = batch[\"labels\"].to(device)\n",
        "\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            val_loss += loss.item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_dataloader)\n",
        "    val_losses.append(avg_val_loss)\n",
        "    print(f\"Epoch {epoch + 1}, Validation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "    # Early Stopping 체크\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        patience_counter = 0  # 개선 시 patience 초기화\n",
        "        # 최적 모델 저장\n",
        "        model.save_pretrained(\"./fine_tuned_kogpt2_best\")\n",
        "        tokenizer.save_pretrained(\"./fine_tuned_kogpt2_best\")\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "\n",
        "    if patience_counter >= early_stopping_patience:\n",
        "        print(\"Early stopping triggered\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWynUSEAybYu",
        "outputId": "4147ee8e-5b79-4dc8-d07c-5603833c4def"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Training Loss: 14.3567\n",
            "Epoch 1, Validation Loss: 6.1436\n",
            "Epoch 2, Training Loss: 3.6549\n",
            "Epoch 2, Validation Loss: 0.4046\n",
            "Epoch 3, Training Loss: 0.4233\n",
            "Epoch 3, Validation Loss: 0.4814\n",
            "Epoch 4, Training Loss: 0.5073\n",
            "Epoch 4, Validation Loss: 0.4994\n",
            "Epoch 5, Training Loss: 0.4720\n",
            "Epoch 5, Validation Loss: 0.4626\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in train_dataloader:\n",
        "    print(tokenizer.decode(batch[\"input_ids\"][0], skip_special_tokens=False))\n",
        "    print(tokenizer.decode(batch[\"labels\"][0], skip_special_tokens=False))\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmx54G_qJnP3",
        "outputId": "52466c98-5fdb-458d-b882-955355919322"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[caption] 밤하늘의 별 [name] 별 [i_action] 반짝이다 [classification] 예술경험 [outcomeResolution] 별은 밤하늘에서 더 반짝이게 되었다. [prediction] <empty> [character] 반짝이는 별 [setting] <empty> [feeling] 감탄 [causalRelationship] <empty> [action] 빛나다 causalRelationship feeling action setting outcomeResolution character prediction<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "별은 밤하늘에서 반짝이고 있었습니다.<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# 모델 저장\n",
        "output_dir = \"./fine_tuned_kogpt2_best\"\n",
        "model.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "print(f\"Model saved to {output_dir}\")\n",
        "'''"
      ],
      "metadata": {
        "id": "g4NzHMAXybbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)  # 모델을 디바이스로 이동"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ0KtehTDIzM",
        "outputId": "aa390171-acba-4e4a-8b55-6d628e751c94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(51212, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2SdpaAttention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=51212, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU가 있으면 GPU로 이동, 없으면 CPU 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"./fine_tuned_kogpt2_best\").to(device)\n",
        "\n",
        "def generate_story(input_text, model, tokenizer, max_length=100):\n",
        "    model.eval()\n",
        "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "        input_ids.to(device),  # 모델과 동일한 디바이스로 이동\n",
        "        max_length=max_length,  # 최대 길이 설정\n",
        "        pad_token_id=tokenizer.pad_token_id,  # 패딩 토큰 설정\n",
        "        eos_token_id=tokenizer.eos_token_id,  # 종료 토큰 설정\n",
        "        bos_token_id=tokenizer.bos_token_id,  # 시작 토큰 설정\n",
        "        repetition_penalty=1.2,  # 반복 패널티 적용 (1.0보다 큰 값으로 설정)\n",
        "        temperature=0.7,  # 생성의 무작위성 조절 (0.7~1.0 추천)\n",
        "        top_k=50,  # 확률이 높은 K개의 단어 중 샘플링\n",
        "        top_p=0.9,  # 누적 확률이 높은 단어만 선택\n",
        "        do_sample=True  # 샘플링 활성화\n",
        ")\n",
        "\n",
        "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "test_text = \"[caption] 숲속의 나비 [name] 나비 [i_action] 날다 [classification] 자연탐구\"\n",
        "generated_story = generate_story(test_text, model, tokenizer)\n",
        "print(\"Generated Story:\", generated_story)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M3dCJ6Jymnw",
        "outputId": "787c50c7-0e8b-40af-ef4e-49037c3d5bf0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Story: 숲속의 나비  나비  날다  자연탐구\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "\n",
        "# BLEU 점수 계산 함수\n",
        "def calculate_bleu_score(reference_texts, generated_texts):\n",
        "    bleu_scores = []\n",
        "    smoothie = SmoothingFunction().method4  # 부드러운 점수 계산 적용\n",
        "\n",
        "    for ref, gen in zip(reference_texts, generated_texts):\n",
        "        ref_tokens = ref.split()\n",
        "        gen_tokens = gen.split()\n",
        "        score = sentence_bleu([ref_tokens], gen_tokens, smoothing_function=smoothie)\n",
        "        bleu_scores.append(score)\n",
        "\n",
        "    return sum(bleu_scores) / len(bleu_scores)\n",
        "\n",
        "# 평가 샘플 테스트\n",
        "reference_texts = df_val['target_text'].tolist()\n",
        "generated_texts = [generate_story(text, model, tokenizer) for text in df_val['input_text'].tolist()]\n",
        "\n",
        "bleu_score = calculate_bleu_score(reference_texts, generated_texts)\n",
        "print(f\"BLEU Score: {bleu_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGVXJEz2Nne0",
        "outputId": "6b462d8e-1d98-4d39-a930-2022961c8aff"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU Score: 0.0216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee5QZ2WPOA4x",
        "outputId": "f3a5bfbf-48da-43a3-f6be-e840d224f5a4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=5425c7dd1e066fd004694f0ea536caef42b16c443b9b3df83dc7c9d8b09fd968\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "# ROUGE 점수 계산 함수\n",
        "def calculate_rouge_scores(reference_texts, generated_texts):\n",
        "    # 올바른 ROUGE 타입 설정 (하이픈 제거)\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
        "    rouge_1, rouge_2, rouge_l = 0, 0, 0\n",
        "\n",
        "    for ref, gen in zip(reference_texts, generated_texts):\n",
        "        scores = scorer.score(ref, gen)\n",
        "        rouge_1 += scores['rouge1'].fmeasure\n",
        "        rouge_2 += scores['rouge2'].fmeasure\n",
        "        rouge_l += scores['rougeL'].fmeasure\n",
        "\n",
        "    n = len(reference_texts)\n",
        "    return {\n",
        "        \"ROUGE-1\": rouge_1 / n,\n",
        "        \"ROUGE-2\": rouge_2 / n,\n",
        "        \"ROUGE-L\": rouge_l / n\n",
        "    }\n",
        "\n",
        "# ROUGE 평가 실행\n",
        "reference_texts = df_val['target_text'].tolist()\n",
        "generated_texts = [generate_story(text, model, tokenizer) for text in df_val['input_text'].tolist()]\n",
        "\n",
        "rouge_scores = calculate_rouge_scores(reference_texts, generated_texts)\n",
        "print(f\"ROUGE Scores: {rouge_scores}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29OOAIDrNpNF",
        "outputId": "d3d154cd-f14a-4c74-8daf-8eb07af52890"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE Scores: {'ROUGE-1': 0.0, 'ROUGE-2': 0.0, 'ROUGE-L': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, PreTrainedTokenizerFast\n",
        "\n",
        "# 모델 로드\n",
        "model_path = \"./fine_tuned_kogpt2_best\"\n",
        "loaded_model = GPT2LMHeadModel.from_pretrained(model_path)\n",
        "loaded_tokenizer = PreTrainedTokenizerFast.from_pretrained(model_path)\n",
        "\n",
        "# 모델의 임베딩 크기 확인\n",
        "print(\"Vocab Size (Model):\", loaded_model.config.vocab_size)\n",
        "print(\"Vocab Size (Tokenizer):\", len(loaded_tokenizer))\n",
        "\n",
        "# 출력된 모델과 토크나이저의 vocab size 일치 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2_eYvuqSNmW",
        "outputId": "253e5130-3f63-4052-988c-74daa10d2fb1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab Size (Model): 51212\n",
            "Vocab Size (Tokenizer): 51212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저 테스트\n",
        "encoded = tokenizer.encode(test_text, return_tensors=\"pt\")\n",
        "print(\"Encoded input:\", encoded)\n",
        "decoded = tokenizer.decode(encoded[0])\n",
        "print(\"Decoded input:\", decoded)\n",
        "\n",
        "# 토크나이저가 데이터를 정확히 인코딩 및 디코딩하는 것 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O0bQ1ZkEObA",
        "outputId": "5522bd02-af75-4113-95be-695a84ace881"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded input: tensor([[51200, 47498, 19842,   739, 51201, 19842,   739, 51202,  9673,  7182,\n",
            "           739, 51203,  9632, 32601]])\n",
            "Decoded input: [caption] 숲속의 나비 [name] 나비 [i_action] 날다 [classification] 자연탐구\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. 문제점**\n",
        "- 입력 그대로 출력됨...\n",
        "  - 너무 적은 데이터로 학습시켜서?\n",
        "  - 하이퍼파라미터 조정?\n",
        "  - 특수 토큰을 단순한 텍스트로 학습할 가능성"
      ],
      "metadata": {
        "id": "wiDMrsp3La_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이전 결과 삭제\n",
        "'''\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "shutil.rmtree(\"./results\", ignore_errors=True)\n",
        "'''"
      ],
      "metadata": {
        "id": "Myo9L3Sm2r0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 기존 모델 폴더 삭제\n",
        "model_dir = \"./fine_tuned_kogpt2_best\"\n",
        "if os.path.exists(model_dir):\n",
        "    shutil.rmtree(model_dir)\n",
        "    print(f\"Deleted existing directory: {model_dir}\")\n",
        "else:\n",
        "    print(f\"No directory found at: {model_dir}\")\n",
        "'''\n"
      ],
      "metadata": {
        "id": "ma4OVHJdFPS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kcU78s8nPRkv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}